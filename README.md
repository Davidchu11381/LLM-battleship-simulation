# ğŸš€ LLM Agent Network Framework

Multi-agent AI battleship with **persistent memory** and **authentic decision-making**. Teams of AI agents strategize, communicate, and adapt using accumulated battlefield intelligence.

## ğŸ¯ What it does

AI agents play adversarial battleship with **100% authentic decision-making** - no predefined moves or scripted strategies. Agents remember past attacks, learn enemy patterns, and make strategic decisions through genuine AI reasoning.

**Key Features:**
- **Authentic AI decisions** - all coordinates chosen by AI reasoning, not fallbacks
- **Persistent memory** - agents remember attacks, patterns, and strategic insights  
- **Personality-driven behavior** - decision-making based on risk tolerance, team reliance, leadership style
- **Multi-model support** - mix local (Ollama) and cloud (OpenAI/Claude/Gemini) models
- **Team strategy** - leaders coordinate, players consult AI assistants and teammates
- **Real-time adaptation** - strategies evolve based on battlefield intelligence

## ğŸ“ Project Structure

```
LLM-Agent-Network/
â”œâ”€â”€ agent_network.py          # Core framework
â”œâ”€â”€ battleship_game.py        # Battleship game engine with memory
â”œâ”€â”€ battleship_runner.py      # Main battleship runner
â”œâ”€â”€ memory_manager.py         # Persistent memory system for agents
â”œâ”€â”€ battleship_config.json   # Game settings & teams
â”œâ”€â”€ LLM_config.json          # Agent configurations
â”œâ”€â”€ networks/
â”‚   â”œâ”€â”€ battleship.txt       # Battleship network topology
â”‚   â”œâ”€â”€ full_mesh.txt        # Full connectivity testing
â”‚   â””â”€â”€ simple.txt           # Basic 2-agent testing
â”œâ”€â”€ output/                  # Generated logs & results
â””â”€â”€ README.md
```

## ğŸ® Game Overview

**Standard battleship** with AI teams that think, strategize, and adapt:
- **10x10 grid** (A1-J10), **5 ships per team** (Carrier to Patrol Boat)
- **Teams of 2-4 agents**: Leaders coordinate, players make attack decisions  
- **AI assistants** provide strategic analysis and coordinate suggestions
- **Win condition**: First team to sink all enemy ships

## ğŸ§  How Agents Think

**Memory-Driven Decisions**: Every agent maintains battlefield intelligence - past attacks, enemy patterns, team strategies. No duplicates, pure strategic reasoning.

**Authentic AI Process**:
```
1. Consultation â†’ AI assistant + team discussion
2. Memory Context â†’ Past attacks, enemy patterns, strategic insights  
3. Personality Analysis â†’ Risk tolerance, team reliance, decision speed
4. AI Reasoning â†’ Genuine strategic coordinate selection
5. Execution â†’ Attack, update memories, share intelligence
```

## ğŸ¯ Game Flow & Phases

### **Phase 1: Ship Placement** 
```
1. Team Leader Discussion (configurable rounds)
   - Leader asks: "Where should we place our Carrier (5 spaces)? Edge or center?"
   - Team members provide input on ship placement strategy
   - Leader makes final decisions based on team consensus

2. Automatic Ship Placement
   - Ships are randomly placed for simulation efficiency
   - Real implementation could use AI-driven placement
```

### **Phase 2: Battle Rounds**
```
Round Structure:
â”œâ”€â”€ Team A Turn
â”‚   â”œâ”€â”€ Player A1 Individual Turn
â”‚   â”‚   â”œâ”€â”€ 1. Consultation Phase
â”‚   â”‚   â”‚   â”œâ”€â”€ AI Assistant Consultation (if available)
â”‚   â”‚   â”‚   â””â”€â”€ Team Discussion (based on personality)
â”‚   â”‚   â”œâ”€â”€ 2. Advice Consolidation
â”‚   â”‚   â”‚   â””â”€â”€ Gather all AI and team suggestions
â”‚   â”‚   â”œâ”€â”€ 3. Coordinate Decision (Authentic AI)
â”‚   â”‚   â”‚   â”œâ”€â”€ Memory Context: Previous attacks, battlefield intel
â”‚   â”‚   â”‚   â”œâ”€â”€ Personality Profile: Risk tolerance, assistant reliance
â”‚   â”‚   â”‚   â””â”€â”€ Strategic Reasoning: AI chooses coordinate
â”‚   â”‚   â””â”€â”€ 4. Attack Execution & Memory Update
â”‚   â”œâ”€â”€ Player A2 Individual Turn
â”‚   â””â”€â”€ [... all team members take turns]
â”œâ”€â”€ Intel Sharing Phase
â”‚   â”œâ”€â”€ Battlefield intel updated for all agents
â”‚   â””â”€â”€ Round results shared with teams
â””â”€â”€ Team B Turn (same structure)
```

### **Phase 3: Game Over**
```
- Victory announcement when all ships sunk
- Statistics generation and memory export
- Game log saved for analysis
```

## ğŸ’­ Communication Tactics & Strategies

### **AI Assistant Consultation**
```python
# Example AI Assistant Prompt
"""Battle situation:
Round: 3
Your Team: Alpha Fleet
Previous Coordinates: A1, B2, C3

Suggest coordinate for attack.
Format: COORDINATE: [A1] - REASONING: [why]
Maximum 25 words."""
```

### **Team Discussion Questions** (Dynamic Based on Game State)
**Early Game (< 3 attempts):**
- "Should I target center areas or edges first?"
- "Go systematic or random hunting?"

**Mid Game (3-8 attempts):**
- "Continue current search pattern or switch zones?"
- "Focus on unexplored areas or follow up on hits?"

**Late Game (8+ attempts):**
- "Any patterns you noticed in their ship placement?"
- "Should I target near previous hits or try new area?"

### **Communication Flow**
```
Player Turn Communication:
1. AI Assistant Consultation (if has_assistant = true)
   â””â”€â”€ Strategic analysis and coordinate suggestion

2. Team Discussion (based on assistant_reliance level)
   â”œâ”€â”€ HIGH reliance: Minimal team consultation
   â”œâ”€â”€ MEDIUM reliance: Balanced AI + team input
   â””â”€â”€ LOW reliance: Extensive team discussion

3. Advice Consolidation
   â””â”€â”€ AI weighs all suggestions based on personality profile
```

## ğŸ­ Personality Profiles & Decision Making

### **Personality Dimensions**
- **`assistant_reliance`**: `high` (follows AI advice), `medium` (balanced), `low` (prefers team input)
- **`decision_speed`**: `fast` (instinctual), `medium` (considers input), `slow` (careful analysis)
- **`risk_tolerance`**: `high` (center attacks), `medium` (balanced), `low` (systematic edges)
- **`leadership_style`**: `collaborative` (team consensus), `authoritative` (AI analysis preferred)

### **Authentic Decision Logic**
```python
# AI Decision Prompt (Profile-Driven)
COORDINATE SELECTION - analytical player

FORBIDDEN: A1, B2, C3, D4  # Already attempted coordinates

BATTLEFIELD MEMORY:
Round 3 intel: Enemy attacks at F7, G3
Global status: 8 coordinates attempted
Remaining targets: 92

ADVICE RECEIVED:
ğŸ¤– assistant_a1: Suggests H9 - Strategic center targeting
ğŸ‘¥ teammate_1: Focus on unexplored quadrants

PROFILE: analytical_player
- Assistant reliance: medium (balance all inputs)
- Risk tolerance: high
- Decision speed: medium

Choose your attack coordinate. Avoid forbidden coordinates.
REQUIRED FORMAT: COORDINATE: [X#]
```

## ğŸ”„ Memory-Driven Adaptation

### **Battlefield Intel Updates** (After Each Attack)
```json
{
  "type": "battlefield_intel", 
  "content": "TURN INTEL: player_a1 attacked E5 â†’ HIT (sunk Destroyer)",
  "round": 3,
  "agents_updated": ["player_a1", "assistant_a1", "all_opponents"]
}
```

### **Cross-Team Intelligence Sharing**
- **Own Team**: Full attack results and strategic insights
- **Enemy Team**: Limited intel about opponent activity
- **Assistants**: Updated with their player's memory context

### **Memory Context in Decisions**
```
BATTLEFIELD MEMORY:
Enemy team (Bravo Fleet) attempted: F7, F4, D5
Global battlefield status: 13 coordinates attempted by both teams
Strategic note: Use this intel to avoid already-attempted coordinates.
```

## ğŸš€ Quick Start

### 1. Install Dependencies
```bash
pip install ag2[ollama,openai]
```

### 2. Configure API Keys
Create or edit `LLM_config.json` and add your API keys:
```json
{
  "global_config": {
    "api_keys": {
      "openai": "your-openai-key",
      "anthropic": "your-claude-key"
    }
  }
}
```

### 3. Setup Local Models (Optional)
For local Llama models via Ollama:
```bash
# Install and start Ollama
export OLLAMA_HOST=0.0.0.0:11435
ollama serve &
ollama pull llama3.1:8b
```

### 4. Run Battleship Game
```bash
# Create sample configuration and run game
python battleship_runner.py --create-sample
python battleship_runner.py

# Advanced options
python battleship_runner.py --communication-rounds 5 --verbose
```

### 5. Test Basic Network (Optional)
```bash
python3 main.py --rounds 1 --max-turns 2 --edges networks/simple.txt
```

## ğŸ“Š Memory Export & Analytics

```bash
# Export all agent memories after game
game.export_game_memories()  # â†’ battleship_memories_TIMESTAMP.json

# View battlefield intelligence
agent_memory = game.memory_manager.get_agent_memory("player_a1")
print(agent_memory.generate_battlefield_summary())
```

## ğŸ¯ Example Authentic AI Decision

```
COORDINATE DECISION TIME (Profile: analytical player)

BATTLEFIELD MEMORY:
Enemy team (Bravo Fleet) attempted: F7, F4, D5
Global battlefield status: 13 coordinates attempted by both teams
Strategic note: Use this intel to avoid already-attempted coordinates.

ADVICE RECEIVED THIS TURN:
ğŸ‘¥ leader_alpha: Suggests center targeting strategy
ğŸ¤– assistant_a1: Suggests H9 - HIGH PROBABILITY ZONE

PROFILE ANALYSIS:
- Medium AI reliance: Balancing AI suggestion with team strategy
- High risk tolerance: Center attacks preferred
- Medium decision speed: Considering all inputs

AI REASONING: "H9 aligns with assistant analysis and hasn't been attempted. 
Center positioning matches my risk profile. Avoiding all forbidden coordinates."

FINAL DECISION: COORDINATE: [H9]
```

## âš™ï¸ Configuration

**LLM Config** (`LLM_config.json`): Agent definitions and API keys
**Battleship Config** (`battleship_config.json`): Teams, personalities, game settings  
**Network Topology** (`networks/battleship.txt`): Communication patterns

### Sample Team Configuration
```json
{
  "team_alpha": {
    "name": "Alpha Fleet",
    "members": ["player_a1", "player_a2"],
    "leader": "player_a1",
    "color": "blue"
  }
}
```

### Sample Personality Profile
```json
{
  "analytical_player": {
    "description": "analytical player",
    "assistant_reliance": "medium",
    "decision_speed": "medium", 
    "risk_tolerance": "high",
    "leadership_style": "authoritative"
  }
}
```

## ğŸš€ Advanced Features

### Multi-Model Support
- **GPT-4** for strategic leaders
- **Claude** for analytical players  
- **Local Llama** for assistants
- **Gemini** for specific roles

### Authentic AI Decision Pipeline
```
Consultation â†’ Advice Consolidation â†’ Memory Context â†’ Personality Analysis â†’ AI Reasoning â†’ Coordinate Selection
```

### Error Handling & Reliability
- **Retry Logic**: If AI gives invalid coordinate, single retry with clearer prompts
- **Emergency Fallback**: Random selection from valid coordinates if AI fails
- **Memory Validation**: Prevents duplicate attacks through battlefield intel

### Memory Analytics
```python
# Analyze player behavior patterns
behavior_analysis = memory_manager.analyze_player_behavior(
    player_id="player_a1", 
    recent_coordinates=["A1", "B2", "C3"]
)
# â†’ {"coordinate_preference": "Prefers edge attacks", "attack_strategy": "Systematic approach"}
```

## ğŸ® Game Statistics & Logging

### Exported Game Data
- **Complete coordinate history** for each player
- **Communication logs** between all agents
- **Memory snapshots** at each decision point
- **Performance metrics** by team and individual
- **Personality-driven decision analysis**

### Sample Game Output
```
ğŸ® BATTLESHIP GAME COMPLETE!
ğŸ† WINNER: Alpha Fleet
ğŸ“Š Total Rounds: 8
ğŸ“ˆ TEAM PERFORMANCE:
  Alpha Fleet: 2/5 ships lost
  Bravo Fleet: 5/5 ships lost  
ğŸ¯ PLAYER ACTIVITY:
  player_a1: 4 attacks (3 hits, 1 sunk)
  player_a2: 4 attacks (2 hits)
ğŸ’¬ Communication: 24 total interactions
   ğŸ¤– AI consultations: 8
   ğŸ‘¥ Team discussions: 16
```

---

**ğŸ¯ Ready for authentic AI battleship tournaments with persistent memory and adaptive learning!** 

*Agents that think, strategize, remember, and evolve their tactics through genuine AI reasoning.*